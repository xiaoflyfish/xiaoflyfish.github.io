---
title: BufferePool
categories: 
- 学习笔记
- MySQL1
---

Buffer Pool就是数据库的一个内存组件，里面缓存了磁盘上的真实数据，然后我们的Java系统对数据库执行的增删改操作，其实主要就是对这个内存数据结构中的缓存数据执行的

**如何配置你的Buffer Pool的大小**

因为Buffer Pool本质其实就是数据库的一个内存组件，你可以理解为他就是一片内存数据结构，所以这个内存数据结构肯定是 有一定的大小的，不可能是无限大的

这个Buffer Pool默认情况下是128MB，还是有一点偏小了，我们实际生产环境下完全可以对Buffer Pool进行调整

比如我们的数据库如果是16核32G的机器，那么你就可以给Buffer Pool分配个2GB的内存，使用下面的配置就可以了

`[server] innodb_buffer_pool_size = 2147483648`

**数据页：MySQL中抽象出来的数据单位**

我们都知道数据库的核心数据模型就是表+字段+行的概念，也就是说我们都知道数据库里有一个一个的表，一个表有很多字 段，然后一个表里有很多行数据，每行数据都有自己的字段值

MySQL对数据抽象出来了一个数据页的概念，他是把很多行数据放在了一个数据页里，也就是说我们的磁盘文件中就是会有很多的数据页，每一页数据里放了很多行数据

所以实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页 直接给加载到Buffer Pool里去 也就是说，Buffer Pool中存放的是一个一个的数据页

**磁盘上的数据页和Buffer Pool中的缓存页是如何对应起来的**

 实际上默认情况下，磁盘中存放的数据页的大小是16KB，也就是说，一页数据包含了16KB的内容。

而Buffer Pool中存放的一个一个的数据页，我们通常叫做缓存页，因为毕竟Buffer Pool是一个缓冲池，里面的数据都是从磁 盘缓存到内存去的。

而Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。

**缓存页对应的描述信息是什么**

对于每个缓存页，他实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓 存页的

比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂 八的东西

每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面， 然后各个缓存页放在后面

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210212175324.png" style="zoom:33%;" />

而且这里我们要注意一点，Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字 节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130 多MB的样子，因为他里面还要存放每个缓存页的描述数据

# Free链表

**我们怎么知道哪些缓存页是空闲的呢**

因为默认情况下磁盘上的数据页和缓存页是一 一对应起来的，都是16KB，一个数据页对应一个缓存页

所以我们必须要知道Buffer Pool中哪些缓存页是空闲的状态

所以数据库会为Buffer Pool设计一个free链表，他是一个双向链表数据结构，这个free链表里，每个节点就是一个空闲的缓存 页的描述数据块的地址，也就是说，只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个free链表中

刚开始数据库启动的时候，可能所有的缓存页都是空闲的，因为此时可能是一个空的数据库，一条数据都没有，所以此时所有 缓存页的描述数据块，都会被放入这个free链表中

这个free链表里面就是各个缓存页的描述数据块，只要缓存页是空闲的，那么他们对 应的描述数据块就会加入到这个free链表中，每个节点都会双向链接自己的前后节点，组成一个双向链表。

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210212182618.png" style="zoom:33%;" />

**free链表占用多少内存空间**

这个free链表，他本身其实就是由Buffer Pool里的描述数据块组成的，你可以认为是每个描述数据 块里都有两个指针，一个是`free_pre`，一个是`free_next`，分别指向自己的上一个free链表的节点，以及下一个free链表的节点

通过Buffer Pool中的描述数据块的`free_pre`和`free_next`两个指针，就可以把所有的描述数据块串成一个free链表

对于free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面就存放了free链表的头节点 的地址，尾节点的地址，还有free链表里当前有多少个节点

**如何将磁盘上的页读取到Buffer Pool的缓存页中去**

首先，我们需要从free链表里获取一个描述数据块，然后就可以对应的获取到这个描述数据块对应的空闲缓存页

接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入缓存页的描述数据块里去，比如 这个数据页所属的表空间之类的信息，最后把那个描述数据块从free链表里去除就可以了

**你怎么知道数据页有没有被缓存**

我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从free链表中找到一个 空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从free链表中移除这个描述数据块

但是如果数据页已经被缓存了，那么就会直接使用了。

所以其实数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个key，然后缓存页的地址作为value。

当你要使用一个数据页的时候，通过“表空间号+数据页号”作为key去这个哈希表里查一下，如果没有就读取数据页，如果 已经有了，就说明数据页已经被缓存了

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210302170050.png" style="zoom:25%;" />

# Flush链表

**Buffer Pool中会不会有内存碎片**

因为Buffer Pool大小是你自己定的，很可能Buffer Pool划分完全部的缓存页和描述数据块之后，还剩一点点的内存，这一点 点的内存放不下任何一个缓存页了，所以这点内存就只能放着不能用，这就是内存碎片

数据库在Buffer Pool中划分缓存页的时候，会让所有的缓存页和描述数据块都紧密的挨在一起，这样尽可能减 少内存浪费，就可以尽可能的减少内存碎片的产生了

如果你的Buffer Pool里的缓存页是东一块西一块，那么必然导致缓存页的内存之间有很多内存空隙，这就会有大量的内存碎片 了

**脏数据页到底为什么会脏**

更新Buffer Pool的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据 页里的数据，是不是就不一致了

这个时候，我们就说缓存页是脏数据，脏页

**哪些缓存页是脏页**

数据库在这里引入了另外一个跟free链表类似的flush链表，这个flush链表本质也是通过缓存页的描述数据块中的两个指 针，让被修改过的缓存页的描述数据块，组成一个双向链表

凡是被修改过的缓存页，都会把他的描述数据块加入到flush链表中去，flush的意思就是这些都是脏页，后续都是要flush刷新 到磁盘上去的

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210212193846.png" style="zoom:33%;" />

# LRU链表

**引入LRU链表来判断哪些缓存页是不常用的**

接着我们就要解决下一个问题了，就是你怎么知道哪些缓存页经常被访问，哪些缓存页很少被访问

此时就要引入一个新的LRU链表了，这个所谓的LRU就是Least Recently Used，最近最少使用的意思

通过这个LRU链表，我们可以知道哪些缓存页是最近最少被使用的，那么当你缓存页需要腾出来一个刷入磁盘的时 候，不就可以选择那个LRU链表中最近最少被使用的缓存页了么

**这个LRU链表大致是怎么个工作原理呢**

假设我们从磁盘加载一个数据页到缓存页的时候，就把这个缓存页的描述数据块放到LRU链 表头部去，那么只要有数据的缓存页，他都会在LRU里了，而且最近被加载数据的缓存页，都会放到LRU链表的头部

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210212195630.png" style="zoom:33%;" />

然后假设某个缓存页的描述数据块本来在LRU链表的尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这 个缓存页挪动到LRU链表的头部去，也就是说最近被访问过的缓存页，一定在LRU链表的头部

那么这样的话，当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘

此 时你就直接在LRU链表的尾部找到一个缓存页，他一定是最近最少被访问的那个缓存页

然后你就把LRU链表尾部的那个缓存页刷入磁盘中，然后把你需要的磁盘数据页加载到腾出来的空闲缓存页中就可以 了

## 问题

**预读带来的一个巨大问题**

首先会带来隐患的就是MySQL的预读机制，这个所谓预读机制，说的就是当你从磁盘上加载一个数据页的时候，他可 能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去

举个例子，假设现在有两个空闲缓存页，然后在加载一个数据页的时候，连带着把他的一个相邻的数据页也加载到缓 存里去了，正好每个数据页放入一个空闲缓存页！

但是接下来呢，实际上只有一个缓存页是被访问了，另外一个通过预读机制加载的缓存页，其实并没有人访问，此时 这两个缓存页可都在LRU链表的前面

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210302192753.png" style="zoom:25%;" />

**哪些情况下会触发MySQL的预读机制**

预读机制一下子把相邻的数据页加载进缓存，放入LRU链表前面的隐患了，预读机制加载进来的 缓存页可能根本不会有人访问，结果他却放在了LRU链表的前面，此时可能会把LRU尾部的那些被频繁访问的缓存页刷 入磁盘中

> 到底哪些情况下会触发MySQL的预读机制呢

1.有一个参数是`innodb_read_ahead_threshold`，他的默认值是56，意思就是如果顺序的访问了一个区里的多个 数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区中的所有数据页都加载到缓 存里去

2.如果Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会 直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去

这个机制是通过参数`innodb_random_read_ahead`来控制的，他默认是OFF，也就是这个规则是关闭的

所以默认情况下，主要是第一个规则可能会触发预读机制，一下子把很多相邻区里的数据页加载到缓存里去

**另外一种可能导致频繁被访问的缓存页被淘汰的场景**

> 全表扫描

这个所谓的全表扫描，意思就是类似如下的SQL语句：`SELECT * FROM USERS`

此时他没加任何一个where条件，会导致他直接一下子把这个表里所有的数据页，都从磁盘加载到Buffer Pool里去。 这个时候他可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去！此时可能LRU链表中排在前面的一大 串缓存页，都是全表扫描加载进来的缓存页！那么如果这次全表扫描过后，后续几乎没用到这个表里的数据呢？ 此时LRU链表的尾部，可能全部都是之前一直被频繁访问的那些缓存页！ 然后当你要淘汰掉一些缓存页腾出空间的时候，就会把LRU链表尾部一直被频繁访问的缓存页给淘汰掉了，而留下了 之前全表扫描加载进来的大量的不经常访问的缓存页！

**如果此时缓存页不够了，需要淘汰一些缓存，会怎么样**

直接就是可以找到LRU链表中的冷数据区域的尾部的缓存页，他们肯定是之前被加载进来的，而且加 载进来1s过后都没人访问过，说明这个缓存页压根儿就没人愿意去访问他！他就是冷数据

## 冷热数据分离

真正MySQL在设计LRU链表的时候，采取的实际上是冷热数据 分离的思想

真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由 `innodb_old_blocks_pct`参数控制的，他默认是37，也就是说冷数据占比37%

这个时候，LRU链表实际上看起来是下面这样子的

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210302194931.png" style="zoom:25%;" />

**数据页第一次被加载到缓存的时候**

实际上这个时候，缓存页会被放在冷数据区域的链表头部，也就是第一次把一个数据页加载到缓存 页之后，这个缓存页实际上是被放在也就是冷数据区域的链表头部位置

**冷数据区域的缓存页什么时候会被放入到热数据区域**

MySQL设定了一个规则，他设计了一个`innodb_old_blocks_time`参数，默认值1000，也就是1000毫秒

也就是说，必须是一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链 表头部去

因为假设你加载了一个数据页到缓存去，然后过了1s之后你还访问了这个缓存页，说明你后续很可能会经常要访问 它，这个时间限制就是1s，因此只有1s后你访问了这个缓存页，他才会给你把缓存页放到热数据区域的链表头部去

**LRU链表的热数据区域是如何进行优化的**

LRU链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后3/4部分的缓存页被访问了，才 会给你移动到链表头部去

如果你是热数据区域的前面1/4的缓存页被访问，他是不会移动到链表头部去的

举个例子，假设热数据区域的链表里有100个缓存页，那么排在前面的25个缓存页，他即使被访问了，也不会移动到 链表头部去的。但是对于排在后面的75个缓存页，他只要被访问，就会移动到链表头部去。 这样的话，他就可以尽可能的减少链表中的节点移动了

**定时把LRU尾部的部分缓存页刷入磁盘**

首先第一个时机，并不是在缓存页满的时候，才会挑选LRU冷数据区域尾部的几个缓存页刷入磁盘，而是有一个后台 线程，他会运行一个定时任务，这个定时任务每隔一段时间就会把LRU链表的冷数据区域的尾部的一些缓存页，刷入 磁盘里去，清空这几个缓存页，把他们加入回free链表去！

所以实际上在缓存页没用完的时候，可能就会清空一些缓存页了

**把flush链表中的一些缓存页定时刷入磁盘**

这个后台线程同时也会在MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修 改过的数据，迟早都会刷入磁盘的！

只要flush链表中的一波缓存页被刷入了磁盘，那么这些缓存页也会从flush链表和lru链表中移除，然后加入到free链表 中去！

所以你可以理解为，你一边不停的加载数据到缓存页里去，不停的查询和修改缓存数据，然后free链表中的缓存页不停 的在减少，flush链表中的缓存页不停的在增加，lru链表中的缓存页不停的在增加和移动。

另外一边，你的后台线程不停的在把lru链表的冷数据区域的缓存页以及flush链表的缓存页，刷入磁盘中来清空缓存 页，然后flush链表和lru链表中的缓存页在减少，free链表中的缓存页在增加。

**实在没有空闲缓存页了怎么办**

此时可能所有的free链表都被使用了，然后flush链表中有一大堆被修改过的缓存页，lru链表中有一大堆的缓存页，根 据冷热数据进行了分离，大致是如此的效果。

这个时候如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页， 他一定是最不经常使用的缓存页！然后把他刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去！

# 生产经验

**Buffer Pool在访问的时候需要加锁吗**

然后这多个线程是不是应该会同时去访问Buffer Pool

就是同时去操作里面的缓存页，同时操作一个free链表、 flush链表、lru链表

现在多个线程来并发的访问这个Buffer Pool了，此时他们都是在访问内存里的一些共享的数据结 构，比如说缓存页、各种链表之类的，那么此时是不是必然要进行加锁

对，多线程并发访问一个Buffer Pool，必然是要加锁的，然后让一个线程先完成一系列的操作，比如说加载数据页到 缓存页，更新free链表，更新lru链表，然后释放锁，接着下一个线程再执行一系列的操作

**多线程并发访问加锁，数据库的性能还能好吗**

既然我们已经解决了第一个问题，就是多线程并发访问一个Buffer Pool的时候必然会加锁，然后很多线程可能要串行 着排队，一个一个的依次执行自己要执行的操作，此时数据库的性能还能好吗

应该这么说，即使就一个Buffer Pool，即使多个线程会加锁串行着排队执行，其实性能也差不到哪儿去

因为大部分情况下，每个线程都是查询或者更新缓存页里的数据，这个操作是发生在内存里的，基本都是微秒级的， 很快很快，包括更新free、flush、lru这些链表，他因为都是基于链表进行一些指针操作，性能也是极高的

所以即使每个线程排队加锁，然后执行一系列操作，数据库的性能倒也是还可以的

**MySQL的生产优化经验：多个Buffer Pool优化并发能力**

一般来说，MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个Buffer Pool

但是如果你的机器内存很大，那么你必然会给Buffer Pool分配较大的内存，比如给他个8G内存，那么此时你是同时可 以设置多个Buffer Pool的，比如说下面的MySQL服务器端的配置

` [server] innodb_buffer_pool_size = 8589934592 innodb_buffer_pool_instances = 4`

我们给buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小 就是2GB

这个时候，MySQL在运行的时候就会有4个Buffer Pool了！每个Buffer Pool负责管理一部分的缓存页和描述数据块， 有自己独立的free、flush、lru等链表

这个时候，假设多个线程并发过来访问，那么不就可以把压力分散开来了吗？有的线程访问这个buffer pool，有的线 程访问那个buffer pool

所以这样的话，一旦你有了多个buffer pool之后，你的多线程并发访问的性能就会得到成倍的提升，因为多个线程可 以在不同的buffer pool中加锁和执行自己的操作，大家可以并发来执行了

所以这个在实际生产环境中，设置多个buffer pool来优化高并发访问性能，是mysql一个很重要的优化技巧

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210302214644.png" style="zoom:25%;" />

## 动态调整大小

**buffer pool这种大块头，能在运行期间动态调整大小吗**

因为动态调整buffer pool大小，比如buffer pool本来是8G，运行期间你给调整为16G了，此时是怎么实 现的呢

就是需要这个时候向操作系统申请一块新的16GB的连续内存，然后把现在的buffer pool中的所有缓存页、描述数据 块、各种链表，都拷贝到新的16GB的内存中去。这个过程是极为耗时的，性能很低下，是不可以接受的！

所以就目前讲解的这套原理，buffer pool是绝对不能支持运行期间动态调整大小的

**如何基于chunk机制把buffer pool给拆小呢**

但是MySQL自然会想办法去做一些优化的，他实际上设计了一个chunk机制，也就是说buffer pool是由很多chunk组 成的，他的大小是`innodb_buffer_pool_chunk_size`参数控制的，默认值就是128MB。

所以实际上我们可以来做一个假设，比如现在我们给buffer pool设置一个总大小是8GB，然后有4个buffer pool，那 么每个buffer pool就是2GB，此时每个buffer pool是由一系列的128MB的chunk组成的，也就是说每个buffer pool 会有16个chunk。

然后每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套 free、flush、lru这些链表

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210302215335.png" style="zoom:25%;" />

**基于chunk机制是如何支持运行期间，动态调整buffer pool大小的**

那么现在有了上面讲的这套chunk机制，就可以支持动态调整buffer pool大小了。

比如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就 可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了。

有个这个chunk机制，此时并不需要额外申请16GB的连续内存空间，然后还要把已有的数据进行拷贝。

给大家讲解这个chunk机制，倒不是让大家在数据库运行的时候动态调整buffer pool大小，其实这不是重点，重点是 大家要了解数据库的buffer pool的真实的数据结构，是可以由多个buffer pool组成的，每个buffer pool是多个 chunk组成的，然后你只要知道他运行期间可以支持动态调整大小就可以了

## 设置

通常来说，我们建议一个比较合理的、健康的比例，是给buffer pool设置你的机器内存的50%~60%左右

`buffer pool总大小=(chunk大小 * buffer pool数量)的2倍数`

接着确定了buffer pool的总大小之后，就得考虑一下设置多少个buffer pool，以及chunk的大小了

此时要记住，有一个很关键的公式就是：`buffer pool总大小=(chunk大小 * buffer pool数量)的倍数` 比如默认的chunk大小是128MB，那么此时如果你的机器的内存是32GB，你打算给buffer pool总大小在20GB左右， 那么你得算一下，此时你的buffer pool的数量应该是多少个呢

假设你的buffer pool的数量是16个，这是没问题的，那么此时`chunk大小 * buffer pool的数量 = 16 * 128MB = 2048MB`，然后buffer pool总大小如果是20GB，此时buffer pool总大小就是2048MB的10倍，这就符合规则了

当然，此时你可以设置多一些buffer pool数量，比如设置32个buffer pool，那么此时buffer pool总大小（20GB）就 是`（chunk大小128MB * 32个buffer pool）`的5倍，也是可以的。 那么此时你的buffer pool大小就是20GB，然后buffer pool数量是32个，每个buffer pool的大小是640MB，然后每 个buffer pool包含5个128MB的chunk，算下来就是这么一个结果了

**SHOW ENGINE INNODB STATUS**

当你的数据库启动之后，你随时可以通过上述命令，去查看当前innodb里的一些具体情况

执行SHOW ENGINE INNODB STATUS就可以了，此时你可能会看到如下一系列的东西

主要讲解这里跟buffer pool相关的一些东西

（1）Total memory allocated，这就是说buffer pool最终的总大小是多少 

（2）Buffer pool size，这就是说buffer pool一共能容纳多少个缓存页 

（3）Free buffers，这就是说free链表中一共有多少个空闲的缓存页是可用的 

（4）Database pages和Old database pages，就是说lru链表中一共有多少个缓存页，以及冷数据区域里的缓存页 数量 

（5）Modified db pages，这就是flush链表中的缓存页数量 

（6）Pending reads和Pending writes，等待从磁盘上加载进缓存页的数量，还有就是即将从lru链表中刷入磁盘的数 量、即将从flush链表中刷入磁盘的数量 

（7）Pages made young和not young，这就是说已经lru冷数据区域里访问之后转移到热数据区域的缓存页的数 量，以及在lru冷数据区域里1s内被访问了没进入热数据区域的缓存页的数量 

（8）youngs/s和not youngs/s，这就是说每秒从冷数据区域进入热数据区域的缓存页的数量，以及每秒在冷数据区 域里被访问了但是不能进入热数据区域的缓存页的数量 

（9）Pages read xxxx, created xxx, written xxx，xx reads/s, xx creates/s, 1xx writes/s，这里就是说已经读取、 创建和写入了多少个缓存页，以及每秒钟读取、创建和写入的缓存页数量 

（10）Buffer pool hit rate xxx / 1000，这就是说每1000次访问，有多少次是直接命中了buffer pool里的缓存的 

（11）young-making rate xxx / 1000 not xx / 1000，每1000次访问，有多少次访问让缓存页从冷数据区域移动到 了热数据区域，以及没移动的缓存页数量 

（12）LRU len：这就是lru链表里的缓存页的数量 

（13）I/O sum：最近50s读取磁盘页的总数 

（14）I/O cur：现在正在读取磁盘页的数量