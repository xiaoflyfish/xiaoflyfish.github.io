---
title: 并发编程1
categories: 
- 学习笔记

---

# 线程基础

[为何说只有 1 种实现线程的方法](https://my.oschina.net/PrivateO2/blog/4643944)

[如何正确的停止线程](https://my.oschina.net/PrivateO2/blog/4649598)

[线程的六种状态](https://my.oschina.net/PrivateO2/blog/4652046)

[wait/notify/notifyAll方法的使用注意事项](https://my.oschina.net/PrivateO2/blog/4653514)

[实现生产者消费者模式的几种方法](https://my.oschina.net/PrivateO2/blog/4657115)

# 线程安全

[常见的三类线程安全问题](https://my.oschina.net/PrivateO2/blog/4713389)

[额外需要注意线程安全的场景](https://my.oschina.net/PrivateO2/blog/4714745)

[多线程带来性能消耗的原因](https://my.oschina.net/PrivateO2/blog/4715143)

# 线程池

[使用线程池比手动创建线程好在哪里](https://my.oschina.net/PrivateO2/blog/4716328)

[线程池的各个参数的含义](https://my.oschina.net/PrivateO2/blog/4716455)

[线程池的四种默认拒绝策略](https://my.oschina.net/PrivateO2/blog/4717446)

[几种常见的线程池](https://my.oschina.net/PrivateO2/blog/4718696)

[线程池中常用的阻塞队列](https://my.oschina.net/PrivateO2/blog/4720518)

[为什么不推荐自动创建线程池](https://my.oschina.net/PrivateO2/blog/4721688)

[如何定制线程池](https://my.oschina.net/PrivateO2/blog/4721851)

[如何正确关闭线程池](https://my.oschina.net/PrivateO2/blog/4723736)

[线程池中线程复用原理](https://blog.csdn.net/fangmeng1997/article/details/107965705)

# 锁

[锁的分类](https://my.oschina.net/PrivateO2/blog/4730766)

[悲观锁、乐观锁](https://my.oschina.net/PrivateO2/blog/4739959)

[synchronized 的 monitor 锁](https://my.oschina.net/PrivateO2/blog/4745994)

[synchronized 与 Lock对比](https://my.oschina.net/PrivateO2/blog/4756429)

[Lock接口常用方法](https://my.oschina.net/PrivateO2/blog/4759249)

[公平锁、非公平锁](https://my.oschina.net/PrivateO2/blog/4773455)

[ReadWriteLock（读写锁）](https://my.oschina.net/PrivateO2/blog/4777080)

[自旋锁](https://my.oschina.net/PrivateO2/blog/4782992)

[JVM 对 synchronized 内置锁进行的优化](https://my.oschina.net/PrivateO2/blog/4795130)

# 并发容器

[HashMap为什么是线程不安全的](https://my.oschina.net/PrivateO2/blog/4835323)

[ConcurrentHashMap 在 Java7 和 8 中的异同点](https://my.oschina.net/PrivateO2/blog/4870078)

[为什么 Map 桶中超过 8 个才转为红黑树](https://my.oschina.net/PrivateO2/blog/4884034)

[ConcurrentHashMap 和 Hashtable 的区别](https://my.oschina.net/PrivateO2/blog/4926025)

[CopyOnWriteArrayList](https://my.oschina.net/PrivateO2/blog/4957201)

# 阻塞队列

[什么是阻塞队列](https://blog.csdn.net/vincent_wen0766/article/details/108580789)

[阻塞队列包含哪些常用的方法](https://blog.csdn.net/vincent_wen0766/article/details/108581381)

[有哪几种常见的阻塞队列](https://blog.csdn.net/vincent_wen0766/article/details/108582100)

[阻塞队列和非阻塞队列的并发安全原理是什么](https://blog.csdn.net/vincent_wen0766/article/details/108593309)

[如何选择适合自己的阻塞队列](https://blog.csdn.net/vincent_wen0766/article/details/108593587)

# 原子类

[原子类是如何利用 CAS 保证线程安全的](https://blog.csdn.net/vincent_wen0766/article/details/108594087)

[AtomicInteger 在高并发下性能不好，如何解决？为什么](https://blog.csdn.net/vincent_wen0766/article/details/108595120)

[原子类和 volatile 有什么异同](https://blog.csdn.net/vincent_wen0766/article/details/108595687)

[AtomicInteger 和 synchronized 的异同点](https://blog.csdn.net/vincent_wen0766/article/details/108596173)

[Java 8 中 Adder 和 Accumulator 有什么区别](https://blog.csdn.net/vincent_wen0766/article/details/108596485)

# ThreadLocal

[ThreadLocal 适合用在哪些实际生产的场景中](https://blog.csdn.net/vincent_wen0766/article/details/108596723)

[ThreadLocal 是用来解决共享资源的多线程访问的问题吗](https://blog.csdn.net/vincent_wen0766/article/details/108598801)

[多个 ThreadLocal 在 Thread 中的 threadlocals 里是怎么存储的](https://blog.csdn.net/vincent_wen0766/article/details/108598994)

[为何每次用完 ThreadLocal 都要调用 remove()](https://blog.csdn.net/vincent_wen0766/article/details/108599292)

# Future

[Callable 和 Runnable 的不同](https://blog.csdn.net/vincent_wen0766/article/details/108599742)

[Future 的主要功能是什么](https://blog.csdn.net/vincent_wen0766/article/details/108599996)

[使用 Future 有哪些注意点？Future 产生新的线程了吗](https://blog.csdn.net/vincent_wen0766/article/details/108600826)

[如何利用 CompletableFuture 实现“旅游平台”问题](https://blog.csdn.net/vincent_wen0766/article/details/108601201)

# 线程协作

[信号量能被 FixedThreadPool 替代吗](https://blog.csdn.net/vincent_wen0766/article/details/108601870)

[CountDownLatch 是如何安排线程执行顺序的](https://blog.csdn.net/vincent_wen0766/article/details/108602685)

[CyclicBarrier 和 CountdownLatch 有什么异同](https://blog.csdn.net/vincent_wen0766/article/details/108603081)

[Condition、object.wait() 和 notify() 的关系](https://blog.csdn.net/vincent_wen0766/article/details/108603643)

[volatile 的作用是什么？与 synchronized 有什么异同](https://blog.csdn.net/vincent_wen0766/article/details/108614886)

# Java内存模型

## 内存模型

**为什么需要 JMM（Java Memory Model，Java 内存模型）**

在更早期的语言中，其实是不存在内存模型的概念的

所以程序最终执行的效果会依赖于具体的处理器，而不同的处理器的规则又不一样，不同的处理器之间可能差异很大，因此同样的一段代码，可能在处理器 A 上运行正常，而在处理器 B 上运行的结果却不一致

同理，在没有 JMM 之前，不同的 JVM 的实现，也会带来不一样的“翻译”结果。

所以 Java 非常需要一个标准，来让 Java 开发者、编译器工程师和 JVM 工程师能够达成一致。达成一致后，我们就可以很清楚的知道什么样的代码最终可以达到什么样的运行效果，让多线程运行结果可以预期，这个标准就是 JMM**，**这就是需要 JMM 的原因。

**JMM 是规范**

JMM 是和多线程相关的一组规范，需要各个 JVM 的实现来遵守 JMM 规范，以便于开发者可以利用这些规范，更方便地开发多线程程序。这样一来，即便同一个程序在不同的虚拟机上运行，得到的程序结果也是一致的。

如果没有 JMM 内存模型来规范，那么很可能在经过了不同 JVM 的“翻译”之后，导致在不同的虚拟机上运行的结果不一样，那是很大的问题。

因此，JMM 与处理器、缓存、并发、编译器有关。它解决了 CPU 多级缓存、处理器优化、指令重排等导致的结果不可预期的问题。

**JMM 是工具类和关键字的原理**

之前我们使用了各种同步工具和关键字，包括 volatile、synchronized、Lock 等，其实它们的原理都涉及 JMM。正是 JMM 的参与和帮忙，才让各个同步工具和关键字能够发挥作用，帮我们开发出并发安全的程序。

比如我们写了关键字 synchronized，JVM 就会在 JMM 的规则下，“翻译”出合适的指令，包括限制指令之间的顺序，以便在即使发生了重排序的情况下，也能保证必要的“可见性”，这样一来，不同的 JVM 对于相同的代码的执行结果就变得可预期了，我们 Java 程序员就只需要用同步工具和关键字就可以开发出正确的并发程序了，这都要感谢 JMM。

## 重排序

**什么是重排序**

假设我们写了一个 Java 程序，包含一系列的语句，我们会默认期望这些语句的实际运行顺序和写的代码顺序一致。但实际上，编译器、JVM 或者 CPU 都有可能出于优化等目的，对于实际指令执行的顺序进行调整，这就是**重排序**。

**重排序的好处：提高处理速度**

**重排序的 3 种情况**

下面我们来看一下重排序的 3 种情况

> 1.编译器优化

编译器（包括 JVM、JIT 编译器等）出于优化的目的，例如当前有了数据 a，把对 a 的操作放到一起效率会更高，避免读取 b 后又返回来重新读取 a 的时间开销，此时在编译的过程中会进行一定程度的重排。不过重排序并不意味着可以任意排序，它需要需要保证重排序后，不改变单线程内的语义，否则如果能任意排序的话，程序早就逻辑混乱了。

> 2.CPU 重排序

CPU 同样会有优化行为，这里的优化和编译器优化类似，都是通过乱序执行的技术来提高整体的执行效率。所以即使之前编译器不发生重排，CPU 也可能进行重排，我们在开发中，一定要考虑到重排序带来的后果。

> 3.内存的“重排序”

内存系统内不存在真正的重排序，但是内存会带来看上去和重排序一样的效果，所以这里的“重排序”打了双引号。由于内存有缓存的存在，在 JMM 里表现为主存和本地内存，而主存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。

举个例子，线程 1 修改了 a 的值，但是修改后没有来得及把新结果写回主存或者线程 2 没来得及读到最新的值，所以线程 2 看不到刚才线程 1 对 a 的修改，此时线程 2 看到的 a 还是等于初始值。但是线程 2 却可能看到线程 1 修改 a 之后的代码执行效果，表面上看起来像是发生了重顺序

## 原子操作

**什么是原子性和原子操作**

在编程中，具备原子性的操作被称为原子操作。原子操作是指一系列的操作，要么全部发生，要么全部不发生，不会出现执行一半就终止的情况。

比如转账行为就是一个原子操作，该过程包含扣除余额、银行系统生成转账记录、对方余额增加等一系列操作。虽然整个过程包含多个操作，但由于这一系列操作被合并成一个原子操作，所以它们要么全部执行成功，要么全部不执行，不会出现执行一半的情况。比如我的余额已经扣除，但是对方的余额却不增加，这种情况是不会出现的，所以说转账行为是具备原子性的

而具有原子性的原子操作，天然具备线程安全的特性。

下面我们举一个不具备原子性的例子，比如 i++ 这一行代码在 CPU 中执行时，可能会从一行代码变为以下的 3 个指令：

- 第一个步骤是读取；
- 第二个步骤是增加；
- 第三个步骤是保存。

这就说明 i++ 是不具备原子性的，同时也证明了 i++ 不是线程安全的。

**Java 中的原子操作有哪些**

Java 中的以下几种操作是具备原子性的，属于原子操作：

- 除了 long 和 double 之外的基本类型（int、byte、boolean、short、char、float）的读/写操作，都天然的具备原子性；
- 所有引用 reference 的读/写操作；
- 加了 volatile 后，所有变量的读/写操作（包含 long 和 double）。这也就意味着 long 和 double 加了 volatile 关键字之后，对它们的读写操作同样具备原子性；
- 在` java.concurrent.Atomic` 包中的一部分类的一部分方法是具备原子性的，比如 AtomicInteger 的 incrementAndGet 方法。

**long 和 double 的原子性**

从刚才的 JVM 规范中我们可以知道，long 和 double 的值需要占用 64 位的内存空间，而对于 64 位值的写入，可以分为两个 32 位的操作来进行。

这样一来，本来是一个整体的赋值操作，就可能被拆分为低 32 位和高 32 位的两个操作。如果在这两个操作之间发生了其他线程对这个值的读操作，就可能会读到一个错误、不完整的值。

JVM 的开发者可以自由选择是否把 64 位的 long 和 double 的读写操作作为原子操作去实现，并且规范推荐 JVM 将其实现为原子操作。

当然，JVM 的开发者也有权利不这么做，这同样是符合规范的。

规范同样规定，如果使用 volatile 修饰了 long 和 double，那么其读写操作就必须具备原子性了。同时，规范鼓励程序员使用 volatile 关键字对这个问题加以控制，由于规范规定了对于 volatile long 和 volatile double 而言，JVM 必须保证其读写操作的原子性，所以加了 volatile 之后，对于程序员而言，就可以确保程序正确

**实际开发中**

其实在实际开发中，读取到“半个变量”的情况非常罕见，这个情况在目前主流的 Java 虚拟机中不会出现。因为 JVM 规范虽然不强制虚拟机把 long 和 double 的变量写操作实现为原子操作，但它其实是“强烈建议”虚拟机去把该操作作为原子操作来实现的。

而在目前各种平台下的主流虚拟机的实现中，几乎都会把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要为了避免读到“半个变量”而把 long 和 double 声明为 volatile 的

**原子操作 + 原子操作 != 原子操作**

值得注意的是，简单地把原子操作组合在一起，并不能保证整体依然具备原子性。比如连续转账两次的操作行为，显然不能合并当做一个原子操作，虽然每一次转账操作都是具备原子性的，但是将两次转账合为一次的操作，这个组合就不具备原子性了，因为在两次转账之间可能会插入一些其他的操作，例如系统自动扣费等，导致第二次转账失败，而且第二次转账失败并不会影响第一次转账成功。

## 主内存和工作内存

**CPU 有多级缓存，导致读的数据过期**

由于 CPU 的处理速度很快，相比之下，内存的速度就显得很慢，所以为了提高 CPU 的整体运行效率，减少空闲时间

在 CPU 和内存之间会有 cache 层，也就是缓存层的存在。虽然缓存的容量比内存小，但是缓存的速度却比内存的速度要快得多，其中 L1 缓存的速度仅次于寄存器的速度

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210305224614.png" style="zoom:25%;" />

在图中，从下往上分别是内存，L3 缓存、L2 缓存、L1 缓存，寄存器，然后最上层是 CPU 的 4个核心

从内存，到 L3 缓存，再到 L2 和 L1 缓存，它们距离 CPU 的核心越来越近了，越靠近核心，其容量就越小，但是速度也越快。正是由于缓存层的存在，才让我们的 CPU 能发挥出更好的性能。

其实，线程间对于共享变量的可见性问题，并不是直接由多核引起的，而是由我们刚才讲到的这些 L3 缓存、L2 缓存、L1 缓存，也就是多级缓存引起的：每个核心在获取数据时，都会将数据从内存一层层往上读取，同样，后续对于数据的修改也是先写入到自己的 L1 缓存中，然后等待时机再逐层往下同步，直到最终刷回内存。

**什么是主内存和工作内存**

Java 作为高级语言，屏蔽了 L1 缓存、L2 缓存、L3 缓存，也就是多层缓存的这些底层细节，用 JMM 定义了一套读写数据的规范。我们不再需要关心 L1 缓存、L2 缓存、L3 缓存等多层缓存的问题，我们只需要关心 JMM 抽象出来的主内存和工作内存的概念

<img src="https://s0.lgstatic.com/i/image3/M01/00/EF/Ciqah154fUGAS19LAAGap07f1AU762.png" alt="img" style="zoom:25%;" />

每个线程只能够直接接触到工作内存，无法直接操作主内存，而工作内存中所保存的正是主内存的共享变量的副本，主内存和工作内存之间的通信是由 JMM 控制的

**主内存和工作内存的关系**

JMM 有以下规定：

1.所有的变量都存储在主内存中，同时每个线程拥有自己独立的工作内存，而工作内存中的变量的内容是主内存中该变量的拷贝；

2.线程不能直接读 / 写主内存中的变量，但可以操作自己工作内存中的变量，然后再同步到主内存中，这样，其他线程就可以看到本次修改；

3.主内存是由多个线程所共享的，但线程间不共享各自的工作内存，如果线程间需要通信，则必须借助主内存中转来完成。

正是由于所有的共享变量都存在于主内存中，每个线程有自己的工作内存，其中存储的是变量的副本，所以这个副本就有可能是过期的，我们来举个例子：如果一个变量 x 被线程 A 修改了，只要还没同步到主内存中，线程 B 就看不到，所以此时线程 B 读取到的 x 值就是一个过期的值，这就导致了可见性问题

## happens-before规则

**什么是 happens-before 关系**

Happens-before 关系是用来描述和可见性相关问题的：

如果第一个操作 happens-before 第二个操作（也可以描述为，第一个操作和第二个操作之间满足 happens-before 关系），那么我们就说第一个操作对于第二个操作一定是可见的，也就是第二个操作在执行时就一定能保证看见第一个操作执行的结果

**不具备 happens-before 关系的例子**

我们先来举一个不具备 happens-before 关系的例子，从宏观上进一步理解 happens-before 关系想要表达的内容

```java
public class Visibility {

    int x = 0;

    public void write() {
        x = 1;
    }

    public void read() {
        int y = x;
    }
}
```

代码很简单，类里面有一个 int x 变量 ，初始值为 0，而 write 方法的作用是把 x 的值改写为 1， 而 read 方法的作用则是读取 x 的值。

如果有两个线程，分别执行 write 和 read 方法，那么由于这两个线程之间没有相互配合的机制，所以 write 和 read 方法内的代码不具备 happens-before 关系，其中的变量的可见性无法保证，下面我们用例子说明这个情况。

比如，假设线程 1 已经先执行了 write 方法，修改了共享变量 x 的值，然后线程 2 执行 read 方法去读取 x 的值，此时我们并不能确定线程 2 现在是否能读取到之前线程 1 对 x 所做的修改，线程 2 有可能看到这次修改，所以读到的 x 值是 1，也有可能看不到本次修改，所以读到的 x 值是最初始的 0。既然存在不确定性，那么 write 和 read 方法内的代码就不具备 happens-before 关系。相反，如果第一个操作 happens-before 第二个操作，那么第一个操作对于第二个操作而言一定是可见的

**Happens-before 关系的规则有哪些**

如果分别有操作 x 和操作 y，用 hb(x, y) 来表示 x happens-before y。

> 单线程规则：

在一个单独的线程中，按照程序代码的顺序，先执行的操作 happen-before 后执行的操作。也就是说，如果操作 x 和操作 y 是同一个线程内的两个操作，并且在代码里 x 先于 y 出现，那么有 hb(x, y)

这一个 happens-before 的规则非常重要，因为如果对于同一个线程内部而言，后面语句都不能保证可以看见前面的语句的执行结果的话，那会造成非常严重的后果，程序的逻辑性就无法保证了。

这里有一个注意点，我们之前讲过重排序，那是不是意味着 happens-before 关系的规则和重排序冲突，为了满足 happens-before 关系，就不能重排序了

答案是否定的。其实只要重排序后的结果依然符合 happens-before 关系，也就是能保证可见性的话，那么就不会因此限制重排序的发生。比如，单线程内，语句 1 在语句 2 的前面，所以根据“单线程规则”，语句 1 happens-before 语句 2，但是并不是说语句 1 一定要在语句 2 之前被执行，例如语句 1 修改的是变量 a 的值，而语句 2 的内容和变量 a 无关，那么语句 1 和语句 2 依然有可能被重排序。当然，如果语句 1 修改的是变量 a，而语句 2 正好是去读取变量 a 的值，那么语句 1 就一定会在语句 2 之前执行了

> 锁操作规则（synchronized 和 Lock 接口等）

如果操作 A 是解锁，而操作 B 是对同一个锁的加锁，那么 hb(A, B) 

有线程 A 和线程 B 这两个线程。线程 A 在解锁之前的所有操作，对于线程 B 的对同一个锁的加锁之后的所有操作而言，都是可见的

> volatile 变量规则

对一个 volatile 变量的写操作 happen-before 后面对该变量的读操作。

这就代表了如果变量被 volatile 修饰，那么每次修改之后，其他线程在读取这个变量的时候一定能读取到该变量最新的值。我们之前介绍过 volatile 关键字，知道它能保证可见性，而这正是由本条规则所规定的

> 线程启动规则

Thread 对象的 start 方法 happen-before 此线程 run 方法中的每一个操作

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210305230412.png" style="zoom:25%;" />

左侧区域是线程 A 启动了一个子线程 B，而右侧区域是子线程 B，那么子线程 B 在执行 run 方法里面的语句的时候，它一定能看到父线程在执行` threadB.start() `前的所有操作的结果

> 线程 join 规则

我们知道 join 可以让线程之间等待，假设线程 A 通过调用` threadB.start() `启动了一个新线程 B，然后调用` threadB.join() `，那么线程 A 将一直等待到线程 B 的 run 方法结束（不考虑中断等特殊情况），然后 join 方法才返回

在 join 方法返回后，线程 A 中的所有后续操作都可以看到线程 B 的 run 方法中执行的所有操作的结果，也就是线程 B 的 run 方法里面的操作 happens-before 线程 A 的 join 之后的语句

> 中断规则

对线程 interrupt 方法的调用 happens-before 检测该线程的中断事件。

也就是说，如果一个线程被其他线程 interrupt，那么在检测中断时（比如调用` Thread.interrupted `或者` Thread.isInterrupted `方法）一定能看到此次中断的发生，不会发生检测结果不准的情况

> 并发工具类的规则

线程安全的并发容器（如 HashTable）在 get 某个值时一定能看到在此之前发生的 put 等存入操作的结果。也就是说，线程安全的并发容器的存入操作 happens-before 读取操作。

信号量（Semaphore）它会释放许可证，也会获取许可证。这里的释放许可证的操作 happens-before 获取许可证的操作，也就是说，如果在获取许可证之前有释放许可证的操作，那么在获取时一定可以看到。

Future：Future 有一个 get 方法，可以用来获取任务的结果。那么，当 Future 的 get 方法得到结果的时候，一定可以看到之前任务中所有操作的结果，也就是说 Future 任务中的所有操作 happens-before Future 的 get 操作。

线程池：要想利用线程池，就需要往里面提交任务（Runnable 或者 Callable），这里面也有一个 happens-before 关系的规则，那就是提交任务的操作 happens-before 任务的执行

## 双重检查锁模式

单例模式指的是，保证一个类只有一个实例，并且提供一个可以全局访问的入口。

**为什么需要使用单例模式**

那么我们为什么需要单例呢？其中**一个理由，那就是为了节省内存、节省计算。**因为在很多情况下，我们只需要一个实例就够了，如果出现更多的实例，反而纯属浪费。

下面我们举一个例子来说明这个情况，以一个初始化比较耗时的类来说

```java
public class ExpensiveResource {
    public ExpensiveResource() {
        field1 = // 查询数据库
        field2 = // 然后对查到的数据做大量计算
        field3 = // 加密、压缩等耗时操作
    }
}
```

这个类在构造的时候，需要查询数据库并对查到的数据做大量计算，所以在第一次构造时，我们花了很多时间来初始化这个对象。但是假设数据库里的数据是不变的，我们就可以把这个对象保存在内存中，那么以后开发的时候就可以直接用这同一个实例了，不需要再次构建新实例。如果每次都重新生成新的实例，则会造成更多的浪费，实在没有必要。

接下来看看需要单例的第二个理由，那就是为了保证结果的正确。

比如我们需要一个全局的计数器，用来统计人数，如果有多个实例，反而会造成混乱。

另外呢，就是为了方便管理。很多工具类，我们只需要一个实例，那么我们通过统一的入口，比如通过 getInstance 方法去获取这个单例是很方便的，太多实例不但没有帮助，反而会让人眼花缭乱。

**双重检查锁模式的写法**

```java
public class Singleton {

    private static volatile Singleton singleton;

    private Singleton() {
    }

    public static Singleton getInstance() {
        if (singleton == null) {
            synchronized (Singleton.class) {
                if (singleton == null) {
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

我们先来看第二次的 check，这时你需要考虑这样一种情况，有两个线程同时调用 getInstance 方法，由于 singleton 是空的 ，因此两个线程都可以通过第一重的 if 判断；然后由于锁机制的存在，会有一个线程先进入同步语句，并进入第二重 if 判断 ，而另外的一个线程就会在外面等待。

不过，当第一个线程执行完 new Singleton() 语句后，就会退出 synchronized 保护的区域，这时如果没有第二重 if (singleton == null) 判断的话，那么第二个线程也会创建一个实例，此时就破坏了单例，这肯定是不行的。

而对于第一个 check 而言，如果去掉它，那么所有线程都会串行执行，效率低下，所以两个 check 都是需要保留的

**在双重检查锁模式中为什么需要使用 volatile 关键字**

主要就在于 `singleton = new Singleton()` ，它并非是一个原子操作，事实上，在 JVM 中上述语句至少做了以下这 3 件事：

- 第一步是给 singleton 分配内存空间；
- 然后第二步开始调用 Singleton 的构造函数等，来初始化 singleton；
- 最后第三步，将 singleton 对象指向分配的内存空间（执行完这步 singleton 就不是 null 了）

这里需要留意一下 1-2-3 的顺序，因为存在指令重排序的优化，也就是说第2 步和第 3 步的顺序是不能保证的，最终的执行顺序，可能是 1-2-3，也有可能是 1-3-2。

如果是 1-3-2，那么在第 3 步执行完以后，singleton 就不是 null 了，可是这时第 2 步并没有执行，singleton 对象未完成初始化，它的属性的值可能不是我们所预期的值

假设此时线程 2 进入 getInstance 方法，由于 singleton 已经不是 null 了，所以会通过第一重检查并直接返回，但其实这时的 singleton 并没有完成初始化，所以使用这个实例的时候会报错

使用了 volatile 之后，相当于是表明了该字段的更新可能是在其他线程中发生的，因此应确保在读取另一个线程写入的值时，可以顺利执行接下来所需的操作

在 JDK 5 以及后续版本所使用的 JMM 中，在使用了 volatile 后，会一定程度禁止相关语句的重排序，从而避免了上述由于重排序所导致的读取到不完整对象的问题的发生

# CAS

[什么是 CAS](https://blog.csdn.net/vincent_wen0766/article/details/108679050)

[CAS 和乐观锁的关系，什么时候会用到 CAS](https://blog.csdn.net/vincent_wen0766/article/details/108679270)

[CAS 有什么缺点](https://blog.csdn.net/vincent_wen0766/article/details/108679444)

# 死锁

[死锁的例子演示](https://blog.csdn.net/vincent_wen0766/article/details/108679728)

[发生死锁必须满足哪 4 个条件](https://blog.csdn.net/vincent_wen0766/article/details/108679882)

[如何用命令行和代码定位死锁](https://blog.csdn.net/vincent_wen0766/article/details/108680523)

[有哪些解决死锁问题的策略](https://blog.csdn.net/vincent_wen0766/article/details/108680707)

[经典的哲学家就餐问题](https://blog.csdn.net/vincent_wen0766/article/details/108695806)

# 不变性

[final 的三种用法是什么](https://blog.csdn.net/vincent_wen0766/article/details/108696041)

[为什么加了 final 却依然无法拥有“不变性”](https://blog.csdn.net/vincent_wen0766/article/details/108696365)

[为什么 String 被设计为是不可变的](https://blog.csdn.net/vincent_wen0766/article/details/108696577)

# AQS

[为什么需要 AQS？AQS 的作用和重要性是什么](https://blog.csdn.net/vincent_wen0766/article/details/108718349)

[AQS 的内部原理是什么样的](https://blog.csdn.net/vincent_wen0766/article/details/108718666)

[AQS 在 CountDownLatch 等类中的应用原理是什么](https://blog.csdn.net/vincent_wen0766/article/details/108719115)