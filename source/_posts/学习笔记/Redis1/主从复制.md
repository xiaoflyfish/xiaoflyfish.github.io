---
title: 主从复制
categories: 
- 学习笔记
- Redis1
---

**主从库间如何进行第一次同步**

当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 `replicaof`（Redis 5.0 之前使用` slaveof`）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210219231145.png" style="zoom:33%;" />

> 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备

在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。

从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。

psync 命令包含了主库的 runID 和复制进度 offset 两个参数

- runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为`“?”`。

- offset，此时设为 -1，表示第一次复制。

主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。

从库收到响应后，会记录下这两个参数。

- **FULLRESYNC** 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。

> 在第二阶段，主库将所有数据同步给从库

从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。

主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。

从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。

在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。

> 第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库

具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作

这样一来，主从库就实现同步了。

**主从级联模式分担全量复制时的主库压力**

如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力

我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。

简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。

然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210219231627.png" style="zoom:33%;" />

一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为**基于长连接的命令传播**，可以避免频繁建立连接的开销

**主从库间网络断了怎么办**

增量复制时，主从库之间具体是怎么保持同步的呢

这里的奥妙就在于` repl_backlog_buffer` 这个缓冲区。

我们先来看下它是如何用于增量命令的同步的。

当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入` repl_backlog_buffer `这个缓冲区。

`repl_backlog_buffer `是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。

刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是` master_repl_offset`。主库接收的新写操作越多，这个值就会越大。

同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 `slave_repl_offset` 也在不断增加。正常情况下，这两个偏移量基本相等

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210219231903.png" style="zoom:33%;" />

主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 `slave_repl_offset` 发给主库，主库会判断自己的 `master_repl_offset `和` slave_repl_offset` 之间的差距。

在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，`master_repl_offset `会大于 `slave_repl_offset`。此时，主库只用把 `master_repl_offset` 和 `slave_repl_offset` 之间的命令操作同步给从库就行。

**增量复制的流程:**

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210219232038.png" style="zoom:33%;" />

因为 `repl_backlog_buffer` 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致

因此，我们要想办法避免这一情况，一般而言，我们可以调整 **repl_backlog_size** 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：`缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小`。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 `repl_backlog_size = 缓冲空间大小 * 2`，这也就是 `repl_backlog_size` 的最终值

# 主从不一致

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210226165210.png" style="zoom:33%;" />

那为啥会出现这个坑呢？其实这是因为**主从库间的命令复制是异步进行的**。

那在什么情况下，从库会滞后执行同步命令呢

- 一方面，主从库间的网络可能会有传输延迟，所以从库不能及时地收到主库发送的命令，从库上执行同步命令的时间就会被延后。
- 另一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。

两种解决方法:

- 在硬件环境配置方面，我们要尽量保证主从库间的网络连接状况良好
- 可以开发一个外部程序来监控主从库间的复制进度

因为 Redis 的 **INFO replication 命令**可以查看主库接收写命令的进度信息（`master_repl_offset`）和从库复制写命令的进度信息（`slave_repl_offset`），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从库的进度，然后，我们用 `master_repl_offset` 减去 `slave_repl_offset`，这样就能得到从库和主库间的复制进度差值了

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210226163400.png" style="zoom:33%;" />

# 读取过期数据

我们在使用 Redis 主从集群时，有时会读到过期数据。例如，数据 X 的过期时间是 202010240900，但是客户端在 202010240910 时，仍然可以从从库中读到数据 X。一个数据过期后，应该是被删除的，客户端不能再读取到该数据，但是，Redis 为什么还能在从库中读到过期的数据呢？

**这是由 Redis 的过期数据删除策略引起的**。

- Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。

先说惰性删除策略。当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据。

> 在访问时检查过期时间 (被动)，如果访问的是主库, 那么发现数据过期会删除, 且不返回给客户端. 但是从库的行为与版本有关，3.2之前的不检查过期, 会返回数据, 3.2之后虽然不删除过期数据, 但是返回空值

定期删除策略是指，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。

> 主动定期删除策略每次删除的过期数据不多 (避免影响性能), 所以应用可能读到未来得及删除的数据

只要使用了 Redis 3.2 后的版本，就不会读到过期数据了吗？其实还是会的。

这跟 Redis 用于设置过期时间的命令有关系，**有些命令给数据设置的过期时间在从库上可能会被延后**，导致应该过期的数据又在从库上被读取到了

- EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；
- EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点

为了避免这种情况，我给你的建议是，在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据

**不合理配置项导致的服务挂掉**

这里涉及到的配置项有两个，分别是 protected-mode 和 cluster-node-timeout

> protected-mode 配置项

这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为 yes 时，哨兵实例只能在部署的服务器本地进行访问。当设置为 no 时，其他服务器也可以访问这个哨兵实例。

正因为这样，如果 protected-mode 被设置为 yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终 Redis 服务不可用。

所以，我们在应用主从集群时，要注意将 `protected-mode` 配置项设置为 no，并且将 bind 配置项设置为其它哨兵实例的 IP 地址。这样一来，只有在 bind 中设置了 IP 地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。

配置示例:

```
protected-mode no
bind 192.168.10.3 192.168.10.4 192.168.10.5
```

> cluster-node-timeout 配置项

这个配置项设置了 Redis Cluster 中实例**响应心跳消息的超时时间**。

当我们在 Redis Cluster 集群中为每个实例配置了“一主一从”模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超出 cluster-node-timeout）

实例超时后，就会被 Redis Cluster 判断为异常。而 Redis Cluster 正常运行的条件就是，有半数以上的实例都能正常运行。

所以，如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将` cluster-node-timeout `调大些（例如 10 到 20 秒）