---
title: 集群
categories: 
- 学习笔记
- Redis1
---

切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存

在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢

**如何保存更多数据**

Redis 应对数据量增多的两种方案：

- 纵向扩展（scale up）: 升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU
- 横向扩展（scale out）: 增加当前 Redis 实例的个数

在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择。

**Redis Cluster**

Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。

在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

映射过程:

1. 首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；
2. 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

哈希槽又是如何被映射到具体的 Redis 实例上的呢

- `cluster create` 命令: 平均分布
- `cluster meet` 命令: 手动建立实例间的连接, 形成集群, 再使用 `cluster addslots` 命令, 指定每个实例上的哈希槽个数

数据、哈希槽、实例这三者的映射分布情况

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210220230557.png" style="zoom:33%;" />

**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作**

**客户端如何定位数据**

客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

- 实例有新增或删除，Redis 需要重新分配哈希槽；
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

Redis Cluster 方案提供了一种重定向机制:

- 当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址

```
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
```

如果 Slot 2 中的数据只有一部分迁移到了新的实例，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：

```
GET hello:key
(error) ASK 13320 172.16.19.5:6379
```

**ASK 命令表示两层含义：**

第一，表明 Slot 数据还在迁移中；

第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端

此时，客户端需要给最新实例 发送 ASKING 命令，然后再发送操作命令。

**ASK 命令并不会更新客户端缓存的哈希槽分配信息**

# 脑裂

所谓的脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

**为什么会发生脑裂**

> 第一步：确认是不是数据同步出现了问题

在主从集群中发生数据丢失，**最常见的原因**就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了

如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算 `master_repl_offset` 和 `slave_repl_offset` 的差值。如果从库上的 `slave_repl_offset` 小于原主库的 `master_repl_offset`，那么，我们就可以认定数据丢失是由数据同步未完成导致的。

> 第二步：排查客户端的操作日志，发现脑裂现象

在排查客户端的操作日志时，我们发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库。根据这个迹象，我们就想到了在分布式主从集群发生故障时会出现的一个问题：脑裂。

但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。

那么，为什么我们的数据仍然丢失了呢？

> 第三步：发现是原主库假故障导致的脑裂

我们是采用哨兵机制进行主从切换的，当主从切换发生时，一定是有超过预设数量（quorum 配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。

但是，在切换过程中，既然客户端仍然和原主库通信，这就表明，原主库并没有真的发生故障（例如主库进程挂掉）

**为什么脑裂会导致数据丢失**

主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的**新写数据就丢失了**

**如何应对脑裂问题**

Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。

- min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
- min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。

我们可以把 `min-slaves-to-write` 和 `min-slaves-max-lag` 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，**原主库就会被限制接收客户端请求**，客户端也就不能在原主库中写入新数据了

# 通信开销

Redis Cluster 能保存的数据量以及支撑的吞吐量，跟集群的实例规模密切相关

Redis 官方给出了 Redis Cluster 的规模上限，就是一个集群运行 1000 个实例。

为什么要限定集群规模呢：

- 实例间的通信开销会随着实例规模增加而增大，在集群超过一定规模时（比如 800 节点），集群吞吐量反而会下降。所以，集群的实际规模会受到限制

**实例通信方法和对集群规模的影响**

为了让集群中的每个实例都知道其它所有实例的状态信息，实例之间会按照一定的规则进行通信。这个规则就是 Gossip 协议

Gossip 协议的工作原理：

- 每个实例之间会按照一定的频率，从集群中随机挑选一些实例，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。PING 消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及 Slot 映射表。
- 一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210226182642.png" style="zoom:25%;" />

Gossip 协议可以保证在一段时间后，集群中的每一个实例都能获得其它所有实例的状态信息。

经过刚刚的分析，我们可以很直观地看到，实例间使用 Gossip 协议进行通信时，通信开销受到**通信消息大小**和**通信频率**这两方面的影响

**Gossip 消息大小**

PING 消息: clusterMsgDataGossip 结构体

```c++
typedef struct {
    char nodename[CLUSTER_NAMELEN];  //40字节
    uint32_t ping_sent; //4字节
    uint32_t pong_received; //4字节
    char ip[NET_IP_STR_LEN]; //46字节
    uint16_t port;  //2字节
    uint16_t cport;  //2字节
    uint16_t flags;  //2字节
    uint32_t notused1; //4字节
} clusterMsgDataGossip;
```

每个实例在发送一个 Gossip 消息时，除了会传递自身的状态信息，默认还会传递**集群十分之一实例的状态信息**。

为了让 Slot 映射表能够在不同实例间传播，PING 消息中还带有一个长度为 16,384 bit 的 Bitmap，这个 Bitmap 的每一位对应了一个 Slot，如果某一位为 1，就表示这个 Slot 属于当前实例。这个 **Bitmap** 大小换算成字节后，是 2KB。

PONG 消息和 PING 消息的内容一样，所以，它的大小大约是 12KB。每个实例发送了 PING 消息后，还会收到返回的 PONG 消息，两个消息加起来有 24KB。

- 实例为了维护集群状态一致传输的 PING/PONG 消息，可能要比单个业务请求大
- 随着集群规模增加，这些心跳消息的数量也会越多，会占据一部分集群的网络通信带宽

**实例间通信频率**

Redis Cluster 的实例启动后，默认会**每秒**从本地的实例列表中随机选出 5 个实例，再从这 5 个实例中找出一个最久没有通信的实例，把 PING 消息发送给该实例。这是实例周期性发送 PING 消息的基本做法。

> 问题:

实例选出来的这个最久没有通信的实例，毕竟是从随机选出的 5 个实例中挑选的，这并不能保证这个实例就一定是整个集群中最久没有通信的实例。

可能会出现，有些实例一直没有被发送 PING 消息，**导致它们维护的集群状态已经过期了**。

> 解决:

Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间，已经大于配置项 `cluster-node-timeout` 的一半了（`cluster-node-timeout/2`），就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息。

当集群规模扩大之后，因为网络拥塞或是不同服务器间的流量竞争，会导致实例间的网络通信延迟增加。如果有部分实例无法收到其它实例发送的 PONG 消息，就会引起实例之间频繁地发送 PING 消息，这又会对集群网络通信带来额外的开销了

每秒会发送的 PING 消息数量:

- PING 消息发送数量 = `1 + 10 * 实例数`（最近一次接收 PONG 消息的时间超出 `cluster-node-timeout/2`）

其中，1 是指单实例常规按照每 1 秒发送一个 PING 消息，10 是指每 1 秒内实例会执行 10 次检查，每次检查后会给 PONG 消息超时的实例发送消息。

例子：假设单个实例检测发现，每 100 毫秒有 10 个实例的 PONG 消息接收超时，那么，这个实例每秒就会发送 101 个 PING 消息，约占 1.2MB/s 带宽。如果集群中有 30 个实例按照这种频率发送消息，就会占用 36MB/s 带宽，这就会挤占集群中用于服务正常请求的带宽

**如何降低实例间的通信开销**

降低实例间发送消息的频率

- 每个实例每 1 秒发送一条 PING 消息。这个频率不算高，如果再降低该频率的话，集群中各实例的状态可能就没办法及时传播了。
- 每个实例每 100 毫秒会做一次检测，给 PONG 消息接收超过 `cluster-node-timeout/2` 的节点发送 PING 消息。实例按照每 100 毫秒进行检测的频率，是 Redis 实例默认的周期性检查任务的统一频率，我们一般不需要修改它。

不推荐减小单个消息的大小:

- 因为集群实例依赖 PING、PONG 消息和 Slot 分配信息，来维持集群状态的统一，一旦减小了传递的消息大小，就会导致实例间的通信信息减少，不利于集群维护

控制发送频率:

- cluster-node-timeout 定义了集群实例被判断为故障的心跳超时时间，默认是 15 秒。如果 `cluster-node-timeout` 值比较小，那么，在大规模集群中，就会比较频繁地出现 PONG 消息接收超时的情况，从而导致实例每秒要执行 10 次“给 PONG 消息超时的实例发送 PING 消息”这个操作
- 所以，为了避免过多的心跳消息挤占集群带宽，我们可以调大 `cluster-node-timeout` 值，比如说调大到 20 秒或 25 秒。这样一来， PONG 消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行 10 次心跳发送操作了

为了验证调整 cluster-node-timeout 值后，是否能减少心跳消息占用的集群网络带宽，提个小建议：**你可以在调整 cluster-node-timeout 值的前后，使用 tcpdump 命令抓取实例发送心跳信息网络包的情况**

例子:执行下面的命令后，我们可以抓取到 192.168.10.3 机器上的实例从 16379 端口发送的心跳网络包，并把网络包的内容保存到 `r1.cap` 文件中：

```
tcpdump host 192.168.10.3 port 16379 -i 网卡名 -w /tmp/r1.cap
```

通过分析网络包的数量和大小，就可以判断调整 `cluster-node-timeout` 值前后，心跳消息占用的带宽情况了