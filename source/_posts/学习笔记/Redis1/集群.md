---
title: 集群
categories: 
- 学习笔记
- Redis1
---

切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存

在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢

**如何保存更多数据**

Redis 应对数据量增多的两种方案：

- 纵向扩展（scale up）: 升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU
- 横向扩展（scale out）: 增加当前 Redis 实例的个数

在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择。

**Redis Cluster**

Redis Cluster 方案采用哈希槽（Hash Slot，接下来我会直接称之为 Slot），来处理数据和实例之间的映射关系。

在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

映射过程:

1. 首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；
2. 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

哈希槽又是如何被映射到具体的 Redis 实例上的呢

- `cluster create` 命令: 平均分布
- `cluster meet` 命令: 手动建立实例间的连接, 形成集群, 再使用 `cluster addslots` 命令, 指定每个实例上的哈希槽个数

数据、哈希槽、实例这三者的映射分布情况

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20210220230557.png" style="zoom:33%;" />

**在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作**

**客户端如何定位数据**

客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：

- 实例有新增或删除，Redis 需要重新分配哈希槽；
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

Redis Cluster 方案提供了一种重定向机制:

- 当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址

```
GET hello:key
(error) MOVED 13320 172.16.19.5:6379
```

如果 Slot 2 中的数据只有一部分迁移到了新的实例，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：

```
GET hello:key
(error) ASK 13320 172.16.19.5:6379
```

**ASK 命令表示两层含义：**

第一，表明 Slot 数据还在迁移中；

第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端

此时，客户端需要给最新实例 发送 ASKING 命令，然后再发送操作命令。

**ASK 命令并不会更新客户端缓存的哈希槽分配信息**

# 脑裂

所谓的脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

**为什么会发生脑裂**

> 第一步：确认是不是数据同步出现了问题

在主从集群中发生数据丢失，**最常见的原因**就是主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了

如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算 `master_repl_offset` 和 `slave_repl_offset` 的差值。如果从库上的 `slave_repl_offset` 小于原主库的 `master_repl_offset`，那么，我们就可以认定数据丢失是由数据同步未完成导致的。

> 第二步：排查客户端的操作日志，发现脑裂现象

在排查客户端的操作日志时，我们发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库。根据这个迹象，我们就想到了在分布式主从集群发生故障时会出现的一个问题：脑裂。

但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。

那么，为什么我们的数据仍然丢失了呢？

> 第三步：发现是原主库假故障导致的脑裂

我们是采用哨兵机制进行主从切换的，当主从切换发生时，一定是有超过预设数量（quorum 配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。

但是，在切换过程中，既然客户端仍然和原主库通信，这就表明，原主库并没有真的发生故障（例如主库进程挂掉）

**为什么脑裂会导致数据丢失**

主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的**新写数据就丢失了**

**如何应对脑裂问题**

Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。

- min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
- min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。

我们可以把 `min-slaves-to-write` 和 `min-slaves-max-lag` 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，**原主库就会被限制接收客户端请求**，客户端也就不能在原主库中写入新数据了

