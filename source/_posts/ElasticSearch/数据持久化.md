---
title: 倒排索引
categories: 
- ElasticSearch
---

Elasticsearch底层采用的是`lucene`这个库来实现倒排索引的功能,在lucene的概念里每一条记录称为`document`(文档)，lucene使用`segment`(分段)来存储数据，用`commit point`来记录所有segment的元数据，一条记录要被搜索到，必须写入到`segment`中

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20201229163433.png" alt="img" style="zoom:33%;" />

<img src="https://xiaoflyfish.oss-cn-beijing.aliyuncs.com/image/20201229165825.png" alt="img" style="zoom:33%;" />

**整体流程：**

数据首先写入内存缓存区和`Translog`日志文件中。当你写一条数据doc的时候，一方面写入到内存缓冲区中，一方面同时写入到`Translog`日志文件中

内存缓存区满了或者每隔1秒(默认1秒)，refresh将内存缓存区的数据生成index segment文件并写入文件系统缓存区，此时`index segment`可被打开以供search查询读取，这样文档就可以被搜索到了（**注意，此时文档还没有写到磁盘上**）；然后清空内存缓存区供后续使用

可见，`refresh`实现的是文档从内存缓存区移到文件系统缓存区的过程。

重复上两个步骤，新的segment不断添加到文件系统缓存区，内存缓存区不断被清空，而`translog`的数据不断增加，随着时间的推移，`Translog`文件会越来越大

当`Translog`长度达到一定程度的时候，会触发flush操作，否则默认每隔30分钟也会定时flush

**其主要过程：**

执行refresh操作将内存缓存区中的数据写入到新的segment并写入文件系统缓存区，然后打开本`segment`以供search使用，最后再次清空内存缓存区

一个`commit point`被写入磁盘，这个commit point中标明所有的index segment

文件系统中缓存的所有的`index segment`文件被fsync强制刷到磁盘，当index segment被fsync强制刷到磁盘上以后，就会被打开，供查询使用

translog被清空和删除，创建一个新的translog

**删除和更新**

由于 `segment` 是不可变的，索引删除的时候既不能把文档从 `segment` 删除，也不能修改 `segment` 反映文档的更新。

- 删除操作，会生成一个 `.del` 文件，`commit point` 会包含这个 `.del` 文件。`.del` 文件将文档标识为 `deleted` 状态，在结果返回前从结果集中删除。
- 更新操作，会将原来的文档标识为 `deleted` 状态，然后新写入一条数据。查询时两个文档有可能都被索引到，但是被标记为删除的文档会被从结果集删除。

**segment合并**

`内存缓存区` 每 `refresh` 一次，就会产生一个 `segment`（默认情况下是 1 秒钟产生一个），这样 `segment` 会越来越多，此时会定期执行 **merge**。

- 将多个 `segment` 合并成一个，并将新的 `segment` 写入磁盘；
- 新增一个 `commit point`，标识所有新的 `segment`；
- 新的 `segment` 被打开供搜索使用；
- 删除旧的 `segment`。